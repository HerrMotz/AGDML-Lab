{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb773b4b",
   "metadata": {},
   "source": [
    "# Exercise 10- Stacking\n",
    "\n",
    "In this exercise you will implement an ensemble method by learning a stacked regressor.\n",
    "\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "- Deadline of submission:\n",
    "        21.06.23 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=43681)\n",
    "\n",
    "\n",
    "### Help\n",
    "In case you cannot solve a task, you can use the saved values within the `help` directory:\n",
    "- Load arrays with [Numpy](https://numpy.org/doc/stable/reference/generated/numpy.load.html)\n",
    "```\n",
    "np.load('help/array_name.npy')\n",
    "```\n",
    "- Load functions with [Dill](https://dill.readthedocs.io/en/latest/dill.html)\n",
    "```\n",
    "import dill\n",
    "with open('help/some_func.pkl', 'rb') as f:\n",
    "    func = dill.load(f)\n",
    "```\n",
    "\n",
    "to continue working on the other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d27cc77",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "\n",
    "We will use a real world dataset used for predicting the [quality of red wine](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009).\n",
    "Altough the quality is a discrete value between 0 and 10, we interpret it as a regression task. \n",
    "\n",
    "### Task 1\n",
    "\n",
    "Load the dataset stored in `dataset.csv` and split it into `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b087f8",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T14:04:28.686968871Z",
     "start_time": "2023-06-21T14:04:28.510925500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides   \n0               7.4             0.700         0.00             1.9      0.076  \\\n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1594            6.2             0.600         0.08             2.0      0.090   \n1595            5.9             0.550         0.10             2.2      0.062   \n1596            6.3             0.510         0.13             2.3      0.076   \n1597            5.9             0.645         0.12             2.0      0.075   \n1598            6.0             0.310         0.47             3.6      0.067   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates   \n0                    11.0                  34.0  0.99780  3.51       0.56  \\\n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1594                 32.0                  44.0  0.99490  3.45       0.58   \n1595                 39.0                  51.0  0.99512  3.52       0.76   \n1596                 29.0                  40.0  0.99574  3.42       0.75   \n1597                 32.0                  44.0  0.99547  3.57       0.71   \n1598                 18.0                  42.0  0.99549  3.39       0.66   \n\n      alcohol  quality  \n0         9.4        5  \n1         9.8        5  \n2         9.8        5  \n3         9.8        6  \n4         9.4        5  \n...       ...      ...  \n1594     10.5        5  \n1595     11.2        6  \n1596     11.0        6  \n1597     10.2        5  \n1598     11.0        6  \n\n[1599 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1594</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1595</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1596</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1597</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1598</th>\n      <td>6.0</td>\n      <td>0.310</td>\n      <td>0.47</td>\n      <td>3.6</td>\n      <td>0.067</td>\n      <td>18.0</td>\n      <td>42.0</td>\n      <td>0.99549</td>\n      <td>3.39</td>\n      <td>0.66</td>\n      <td>11.0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>1599 rows Ã— 12 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "df = pd.read_csv(\"dataset.csv\")\n",
    "y = np.array(df['quality'])\n",
    "X = np.array(df.iloc[:,:11])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b222bb8",
   "metadata": {},
   "source": [
    "## $R^2$ Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5683ff45",
   "metadata": {},
   "source": [
    "Sklearn uses the [$R^2$ score](https://en.wikipedia.org/wiki/Coefficient_of_determination) as a quality measure for regressors. Given true values $y$ and predicted values $\\hat{y}$ the $R^2$ score is defined as \n",
    "\n",
    "\\begin{align*}\n",
    "R^2(y, \\hat{y}) &= 1-\\cfrac{\\sum_{i=1}^m(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^m(y_i - \\bar{y})^2}\\,,\n",
    "\\end{align*}\n",
    "where $\\bar{y}$ is the average of $y$.\n",
    "\n",
    "This value is 1 if the predictions match exactly, 0 if we would simply always predict the average and negative if our predictions are worse than this simple baseline.\\\n",
    "In short we aim for a value $>0$ and close to $1$.\n",
    "\n",
    "### Task 2\n",
    "\n",
    "Implement the $R^2$ score.\\\n",
    "Then use scikit learns [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) model to fit on the dataset and calculate the $R^2$ score.\\\n",
    "Compare your result to the `.score` method of the regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6302e258",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T14:04:28.688516026Z",
     "start_time": "2023-06-21T14:04:28.544797797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('R2 score', 0.36055170303868833, '.score', 0.36055170303868833)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def r2_score(X : np.ndarray, y : np.ndarray, y_hat : np.ndarray) -> float:\n",
    "    '''\n",
    "    Calculates coefficient of determination.\n",
    "    \n",
    "    @Params:\n",
    "        X... features // TODO WHY????\n",
    "        y... labels\n",
    "        y_hat.. predictions\n",
    "    \n",
    "    @Returns:\n",
    "        score in (-inf, 1)\n",
    "    '''\n",
    "    \n",
    "    # TODO: implement\n",
    "    return 1 - np.sum((y-y_hat)**2) / np.sum((y-np.mean(y))**2)\n",
    "\n",
    "\n",
    "# TODO: calculate r2 score for linear regressor, compare with .score\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "y_hat = lr.predict(X)\n",
    "\n",
    "score0 = r2_score(None, y, y_hat)\n",
    "score1 = lr.score(X, y)\n",
    "\n",
    "\"R2 score\", score0, \".score\", score1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13700b8d",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "The main idea in stacking is to \n",
    "1. learn several heterogenous base models on the original data\n",
    "2. learn a meta model on the predictions of the base models\n",
    "\n",
    "<div>\n",
    "<img src=\"images/stacking.png\" width=\"600\"/>\n",
    "</div>\n",
    "The hope is that the meta model can learn to combine the strengths of the base models (e.g. if model 1 fails, model 3 is strong).\n",
    "Note that in contrast to bagging and boosting the base models must not be of the same method (e.g. decision trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bdb752",
   "metadata": {},
   "source": [
    "## Base Models\n",
    "\n",
    "First lets select a set of base models. We can now choose from the wide pool of regression methods.\n",
    "\n",
    "Here we want to use the following models:\n",
    "- [Linear Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- Polynomial Regression of degree 2 (use a [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) of [Polynomial Features](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) followed by Linear Regression)\n",
    "- [KNN Regression](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "- [Decision Tree Regression](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2f1a5",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Create a list of base models and evaluate them using crossvalidation (avg. of 10 folds)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3c0d0e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T14:04:29.042225576Z",
     "start_time": "2023-06-21T14:04:28.569126729Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[0.23554709694307557,\n 0.19022921981676175,\n -0.07634595535227609,\n -0.48844774679177255]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: create base models\n",
    "\n",
    "degree = 2\n",
    "alpha = 1e-3\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "knn_regression = KNeighborsRegressor()\n",
    "dtree_regression = DecisionTreeRegressor()\n",
    "polynomial_regression = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "\n",
    "regressors = [linear_regression, polynomial_regression, knn_regression, dtree_regression]\n",
    "scores = []\n",
    "\n",
    "# TODO: estimate avg. crossvalidation score for each base model\n",
    "for r in regressors:\n",
    "    r.fit(X, y)\n",
    "    scores.append(np.mean(cross_val_score(r, X, y, cv=10)))\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174be917",
   "metadata": {},
   "source": [
    "## Meta Model\n",
    "\n",
    "The meta model uses the predictions of the base models to predict $y$. One can thus view the base models as a feature map for the meta model.\n",
    "\n",
    "In order to train the meta model, **we need the predictions of the base models on unseen data** since this is the scenario we would face at inference time. A simple method is to use **out-of-fold predictions** during training:\n",
    "\n",
    "1. separate the data into k folds.\n",
    "2. hold out one of the folds and train the base models on the other folds.\n",
    "3. predict the held out fold using the base models.\n",
    "4. repeat the above two steps k times to obtain out-of-fold predictions for all k folds.\n",
    "5. feed all the out-of-fold prediction as features (training data) to the meta model.\n",
    "\n",
    "\n",
    "### Task 4\n",
    "\n",
    "Implement the out-of-fold method below.\\\n",
    "Calculate the $R^2$-Score on the out-of-fold predictions for each of the base models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa6379c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T14:04:29.252506518Z",
     "start_time": "2023-06-21T14:04:29.030648826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LinearRegression(), Pipeline(steps=[('polynomialfeatures', PolynomialFeatures()),\n",
      "                ('linearregression', LinearRegression())]), KNeighborsRegressor(), DecisionTreeRegressor()]\n"
     ]
    },
    {
     "data": {
      "text/plain": "[0.332343863940908,\n 0.2807938638434405,\n 0.023571220255133585,\n -0.3510335317224569]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def oof_prediction(model : sklearn.base.BaseEstimator, X : np.ndarray, y : np.ndarray, k = 5, permutate : bool = False) -> np.ndarray:\n",
    "    '''\n",
    "    Calculates out-of-fold predictions.\n",
    "    \n",
    "    @Params:\n",
    "        model... class with a .fit and .predict method\n",
    "        X... samples\n",
    "        y... labels\n",
    "        \n",
    "    @Returns:\n",
    "        predictions\n",
    "    '''\n",
    "    # TODO: implement\n",
    "    _length = X.shape[0]\n",
    "    _block_size = np.floor(X.shape[0] / k)\n",
    "\n",
    "    kf = KFold(k, shuffle=permutate)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        _test_X = X[test_index]\n",
    "        _test_y = y[test_index]\n",
    "\n",
    "        _train_X = X[train_index]\n",
    "        _train_y = y[train_index]\n",
    "\n",
    "        model.fit(_train_X, _train_y)\n",
    "        _y_hat = model.predict(_test_X)\n",
    "\n",
    "        # predictions.append({\n",
    "        #     \"predictions\": _y_hat,\n",
    "        #     \"r2_score\": r2_score(None, _test_y, _y_hat)\n",
    "        # })\n",
    "\n",
    "        predictions.append(_y_hat)\n",
    "\n",
    "    return np.concatenate(predictions)\n",
    "\n",
    "k = 10\n",
    "# TODO: calculate r2 score for oof predictions for each base model\n",
    "oof_scores = []\n",
    "for r in regressors:\n",
    "    # for reproducibility\n",
    "    predictions = oof_prediction(r, X, y, k, permutate=False)\n",
    "    oof_scores.append(r2_score(X, y, predictions))\n",
    "\n",
    "print(regressors)\n",
    "oof_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa1f1a9",
   "metadata": {},
   "source": [
    "Now lets put everything together.\n",
    "\n",
    "### Task 5\n",
    "\n",
    "Implement the following `Stacking` class. Keep in mind the following things:\n",
    "- the meta model is trained on out-of-fold predictions of the base models\n",
    "- the base models are trained on the given dataset\n",
    "- when predicting, we just use the predictions of the base models (no out-of-fold) as input for the meta model\n",
    "\n",
    "Use your class to learn a stacked regressor with **linear regression as meta model** and the base models from Task 3. Evaluate it using crossvalidation (avg. of 10 folds) and compare the score to those of the base models (Task 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "1439"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def smallestDivisor(number: int):\n",
    "    divisor = 5\n",
    "    while number % divisor != 0:\n",
    "        divisor+=1\n",
    "    return divisor\n",
    "\n",
    "smallestDivisor(1439) # because it is f****** prime......."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-21T14:04:29.258622672Z",
     "start_time": "2023-06-21T14:04:29.252826042Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71c17292",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T14:04:34.936924420Z",
     "start_time": "2023-06-21T14:04:29.258921357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2379ca6dd3747ec86eae32dff2e6ca3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5af67a98fbb416d905f5dabf369a03e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1335dda757fb4c9ab44f9e0a4d3c8d28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e254f036a7a54587be932562cc2b73f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e33feff401a243469728e658c6ebe878"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f57ada9a6994e4bb3eb8b1bfb1cbf39"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5ad1e1bb6a14682805468d2b209b494"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a1aa35d1af684671be33c2a563ea971b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a46c2ba2d4bc4dabb66d67b14611daaf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "904b5af96be947758f1599e4f180eef9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "403d1e3676ce47ba9e49936fe14a7395"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8928b5e7ba64b40ba4eed7cd632d5c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce5075c3f75e464897daf9bcc8a84166"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d2572946439429ea4eaae40d9394c90"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4436773deb6144f0981e28a552a64369"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b02f3dbdf9a24952bea46598b842d737"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51753ff42ae041358239f612e798cd80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55de6eb791174ede9edbc3e84d424410"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fc90144d548447d91e97a649b15e786"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit base models\n",
      "k=10\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5602d0473a4c42ee87e8ff5c3a2cedc3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c70c98417824ccaa31d70f2d35bc07f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "0.247949445130604"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class StackedRegressor(sklearn.base.BaseEstimator):\n",
    "    \n",
    "    def __init__(self, base_models : list, meta_model : sklearn.base.BaseEstimator):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        \n",
    "    def fit(self, X : np.ndarray, y : np.ndarray):\n",
    "        '''\n",
    "        Learns base and meta models.\n",
    "        \n",
    "        @Params:\n",
    "            X... features\n",
    "            y... labels\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        y_hats = []\n",
    "        # print(X.shape[0])\n",
    "        # k = smallestDivisor(X.shape[0])\n",
    "\n",
    "        print(\"Fit base models\")\n",
    "        print(f\"k={k}\")\n",
    "        for m in tqdm(self.base_models):\n",
    "            # make oof predictions\n",
    "            y_hats.append(oof_prediction(m, X, y, k, permutate=False))\n",
    "\n",
    "            # fit base models on the whole dataset\n",
    "            m.fit(X, y)\n",
    "\n",
    "        self.meta_model.fit(np.stack(y_hats, axis=1), y)\n",
    "        pass\n",
    "    \n",
    "    def predict(self, X : np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Given features, predicts labels.\n",
    "        \n",
    "        @Params:\n",
    "            X... features\n",
    "            \n",
    "        @Returns:\n",
    "            labels as array\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        # feature map with base models\n",
    "        y_hats = []\n",
    "        for m in tqdm(self.base_models):\n",
    "            y_hats.append(m.predict(X))\n",
    "\n",
    "        # predict with metamodel\n",
    "        return self.meta_model.predict(np.stack(y_hats, axis=1))\n",
    "\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        '''\n",
    "        R2-Score, needed for crossvalidation.\n",
    "        \n",
    "        @Params:\n",
    "            X... features\n",
    "            y... labels\n",
    "            \n",
    "        @Returns:\n",
    "            Accuracy when predicting for X.\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        return r2_score(X, y, self.predict(X))\n",
    "\n",
    "# TODO: fit stacked model\n",
    "sr = StackedRegressor(regressors, LinearRegression())\n",
    "sr.fit(X, y)\n",
    "\n",
    "# TODO: evaluate with crossvalidation, compare to base models\n",
    "np.mean(cross_val_score(sr, X, y, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40740021",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Use the [scikit-learn implementation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.StackingRegressor.html) to learn a stacked regressor.\\\n",
    "Evaluate it using crossvalidation (avg. of 10 folds) and compare the score to the scores of task 5.\n",
    "\n",
    "Note that minor differences can occur due to a more advanced oof-prediction used in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f00c97f1",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-06-21T15:03:07.066682087Z",
     "start_time": "2023-06-21T15:02:56.579166544Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/64 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0184eb9693e048fcaa0e60909f6794dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: ['Linear Regression']\n",
      "Training: ['Polynomial Regression']\n",
      "Training: ['KNN Regression']\n",
      "Training: ['Paul ist cool ðŸ˜Ž']\n",
      "Training: ['Kernel Ridge']\n",
      "Training: ['Quantile Regressor']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frand/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/linear_model/_quantile.py:186: FutureWarning: The default solver will change from 'interior-point' to 'highs' in version 1.4. Set `solver='highs'` or to the desired solver to silence this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 45\u001B[0m\n\u001B[1;32m     33\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m     34\u001B[0m             ([a[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m], np\u001B[38;5;241m.\u001B[39mmean(cross_val_score(reg, X, y, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)))\n\u001B[1;32m     35\u001B[0m         )\n\u001B[1;32m     37\u001B[0m estimators \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     38\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLinear Regression\u001B[39m\u001B[38;5;124m'\u001B[39m, linear_regression),\n\u001B[1;32m     39\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPolynomial Regression\u001B[39m\u001B[38;5;124m'\u001B[39m, polynomial_regression),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     43\u001B[0m     (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mQuantile Regressor\u001B[39m\u001B[38;5;124m'\u001B[39m, QuantileRegressor())\n\u001B[1;32m     44\u001B[0m ]\n\u001B[0;32m---> 45\u001B[0m \u001B[43mstacking_regressor_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimators\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[81], line 29\u001B[0m, in \u001B[0;36mstacking_regressor_helper\u001B[0;34m(estimators)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTraining:\u001B[39m\u001B[38;5;124m\"\u001B[39m, [a[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m])\n\u001B[1;32m     24\u001B[0m reg \u001B[38;5;241m=\u001B[39m StackingRegressor(\n\u001B[1;32m     25\u001B[0m     estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mset\u001B[39m,\n\u001B[1;32m     26\u001B[0m     final_estimator\u001B[38;5;241m=\u001B[39mLinearRegression()\n\u001B[1;32m     27\u001B[0m )\n\u001B[0;32m---> 29\u001B[0m \u001B[43mreg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# TODO: evaluate with crossvalidation, compare to custom model\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# print(\", \".join([a[0] for a in set]))\u001B[39;00m\n\u001B[1;32m     33\u001B[0m results\u001B[38;5;241m.\u001B[39mappend(\n\u001B[1;32m     34\u001B[0m     ([a[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m], np\u001B[38;5;241m.\u001B[39mmean(cross_val_score(reg, X, y, cv\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m)))\n\u001B[1;32m     35\u001B[0m )\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:958\u001B[0m, in \u001B[0;36mStackingRegressor.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    936\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the estimators.\u001B[39;00m\n\u001B[1;32m    937\u001B[0m \n\u001B[1;32m    938\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    955\u001B[0m \u001B[38;5;124;03m    Returns a fitted instance.\u001B[39;00m\n\u001B[1;32m    956\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    957\u001B[0m y \u001B[38;5;241m=\u001B[39m column_or_1d(y, warn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m--> 958\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/ensemble/_stacking.py:209\u001B[0m, in \u001B[0;36m_BaseStacking.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    204\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_\u001B[38;5;241m.\u001B[39mappend(estimator)\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;66;03m# Fit the base estimators on the whole training data. Those\u001B[39;00m\n\u001B[1;32m    207\u001B[0m     \u001B[38;5;66;03m# base estimators will be used in transform, predict, and\u001B[39;00m\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;66;03m# predict_proba. They are exposed publicly.\u001B[39;00m\n\u001B[0;32m--> 209\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mestimators_ \u001B[38;5;241m=\u001B[39m \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    210\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_single_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mall_estimators\u001B[49m\n\u001B[1;32m    212\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mest\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m!=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdrop\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m    213\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnamed_estimators_ \u001B[38;5;241m=\u001B[39m Bunch()\n\u001B[1;32m    216\u001B[0m est_fitted_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1076\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1077\u001B[0m     \u001B[38;5;66;03m# Only set self._iterating to True if at least a batch\u001B[39;00m\n\u001B[1;32m   1078\u001B[0m     \u001B[38;5;66;03m# was dispatched. In particular this covers the edge\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1082\u001B[0m     \u001B[38;5;66;03m# was very quick and its callback already dispatched all the\u001B[39;00m\n\u001B[1;32m   1083\u001B[0m     \u001B[38;5;66;03m# remaining jobs.\u001B[39;00m\n\u001B[1;32m   1084\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m-> 1085\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1086\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1088\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m[\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/utils/parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/ensemble/_base.py:46\u001B[0m, in \u001B[0;36m_fit_single_estimator\u001B[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001B[0m\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _print_elapsed_time(message_clsname, message):\n\u001B[0;32m---> 46\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m estimator\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/sklearn/linear_model/_quantile.py:280\u001B[0m, in \u001B[0;36mQuantileRegressor.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    276\u001B[0m         A_eq \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate([X, \u001B[38;5;241m-\u001B[39mX, eye, \u001B[38;5;241m-\u001B[39meye], axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    278\u001B[0m b_eq \u001B[38;5;241m=\u001B[39m y\n\u001B[0;32m--> 280\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mlinprog\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m    \u001B[49m\u001B[43mc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m    \u001B[49m\u001B[43mA_eq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mA_eq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m    \u001B[49m\u001B[43mb_eq\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mb_eq\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msolver_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m solution \u001B[38;5;241m=\u001B[39m result\u001B[38;5;241m.\u001B[39mx\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m result\u001B[38;5;241m.\u001B[39msuccess:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/optimize/_linprog.py:680\u001B[0m, in \u001B[0;36mlinprog\u001B[0;34m(c, A_ub, b_ub, A_eq, b_eq, bounds, method, callback, options, x0, integrality)\u001B[0m\n\u001B[1;32m    676\u001B[0m     x, status, message, iteration \u001B[38;5;241m=\u001B[39m _linprog_simplex(\n\u001B[1;32m    677\u001B[0m         c, c0\u001B[38;5;241m=\u001B[39mc0, A\u001B[38;5;241m=\u001B[39mA, b\u001B[38;5;241m=\u001B[39mb, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[1;32m    678\u001B[0m         postsolve_args\u001B[38;5;241m=\u001B[39mpostsolve_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msolver_options)\n\u001B[1;32m    679\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minterior-point\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m--> 680\u001B[0m     x, status, message, iteration \u001B[38;5;241m=\u001B[39m \u001B[43m_linprog_ip\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m        \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mc0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpostsolve_args\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpostsolve_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msolver_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m meth \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrevised simplex\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    684\u001B[0m     x, status, message, iteration \u001B[38;5;241m=\u001B[39m _linprog_rs(\n\u001B[1;32m    685\u001B[0m         c, c0\u001B[38;5;241m=\u001B[39mc0, A\u001B[38;5;241m=\u001B[39mA, b\u001B[38;5;241m=\u001B[39mb, x0\u001B[38;5;241m=\u001B[39mx0, callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[1;32m    686\u001B[0m         postsolve_args\u001B[38;5;241m=\u001B[39mpostsolve_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39msolver_options)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/optimize/_linprog_ip.py:1122\u001B[0m, in \u001B[0;36m_linprog_ip\u001B[0;34m(c, c0, A, b, callback, postsolve_args, maxiter, tol, disp, alpha0, beta, sparse, lstsq, sym_pos, cholesky, pc, ip, permc_spec, **unknown_options)\u001B[0m\n\u001B[1;32m   1115\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1116\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid option combination \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msym_pos\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:False \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1117\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mand \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcholesky\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m:True: Cholesky decomposition is only possible \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1118\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfor symmetric positive definite matrices.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1120\u001B[0m cholesky \u001B[38;5;241m=\u001B[39m cholesky \u001B[38;5;129;01mor\u001B[39;00m (cholesky \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m sym_pos \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lstsq)\n\u001B[0;32m-> 1122\u001B[0m x, status, message, iteration \u001B[38;5;241m=\u001B[39m \u001B[43m_ip_hsd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha0\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mmaxiter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1124\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mlstsq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msym_pos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcholesky\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mpc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpermc_spec\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1126\u001B[0m \u001B[43m                                        \u001B[49m\u001B[43mpostsolve_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, status, message, iteration\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/optimize/_linprog_ip.py:753\u001B[0m, in \u001B[0;36m_ip_hsd\u001B[0;34m(A, b, c, c0, alpha0, beta, maxiter, disp, tol, sparse, lstsq, sym_pos, cholesky, pc, ip, permc_spec, callback, postsolve_args)\u001B[0m\n\u001B[1;32m    749\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m g\n\u001B[1;32m    751\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    752\u001B[0m     \u001B[38;5;66;03m# Solve [4] 8.6 and 8.7/8.13/8.23\u001B[39;00m\n\u001B[0;32m--> 753\u001B[0m     d_x, d_y, d_z, d_tau, d_kappa \u001B[38;5;241m=\u001B[39m \u001B[43m_get_delta\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    754\u001B[0m \u001B[43m        \u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mz\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtau\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkappa\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgamma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    755\u001B[0m \u001B[43m        \u001B[49m\u001B[43msparse\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlstsq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msym_pos\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcholesky\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mip\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpermc_spec\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    757\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ip:  \u001B[38;5;66;03m# initial point\u001B[39;00m\n\u001B[1;32m    758\u001B[0m         \u001B[38;5;66;03m# [4] 4.4\u001B[39;00m\n\u001B[1;32m    759\u001B[0m         \u001B[38;5;66;03m# Formula after 8.23 takes a full step regardless if this will\u001B[39;00m\n\u001B[1;32m    760\u001B[0m         \u001B[38;5;66;03m# take it negative\u001B[39;00m\n\u001B[1;32m    761\u001B[0m         alpha \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/optimize/_linprog_ip.py:266\u001B[0m, in \u001B[0;36m_get_delta\u001B[0;34m(A, b, c, x, y, z, tau, kappa, gamma, eta, sparse, lstsq, sym_pos, cholesky, pc, ip, permc_spec)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m solved:\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    265\u001B[0m         \u001B[38;5;66;03m# [4] Equation 8.28\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m         p, q \u001B[38;5;241m=\u001B[39m \u001B[43m_sym_solve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDinv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msolve\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    267\u001B[0m         \u001B[38;5;66;03m# [4] Equation 8.29\u001B[39;00m\n\u001B[1;32m    268\u001B[0m         u, v \u001B[38;5;241m=\u001B[39m _sym_solve(Dinv, A, rhatd \u001B[38;5;241m-\u001B[39m\n\u001B[1;32m    269\u001B[0m                           (\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m x) \u001B[38;5;241m*\u001B[39m rhatxs, rhatp, solve)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/optimize/_linprog_ip.py:347\u001B[0m, in \u001B[0;36m_sym_solve\u001B[0;34m(Dinv, A, r1, r2, solve)\u001B[0m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# [4] 8.31\u001B[39;00m\n\u001B[1;32m    346\u001B[0m r \u001B[38;5;241m=\u001B[39m r2 \u001B[38;5;241m+\u001B[39m A\u001B[38;5;241m.\u001B[39mdot(Dinv \u001B[38;5;241m*\u001B[39m r1)\n\u001B[0;32m--> 347\u001B[0m v \u001B[38;5;241m=\u001B[39m \u001B[43msolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;66;03m# [4] 8.32\u001B[39;00m\n\u001B[1;32m    349\u001B[0m u \u001B[38;5;241m=\u001B[39m Dinv \u001B[38;5;241m*\u001B[39m (A\u001B[38;5;241m.\u001B[39mT\u001B[38;5;241m.\u001B[39mdot(v) \u001B[38;5;241m-\u001B[39m r1)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/optimize/_linprog_ip.py:107\u001B[0m, in \u001B[0;36m_get_solver.<locals>.solve\u001B[0;34m(r)\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msolve\u001B[39m(r):\n\u001B[0;32m--> 107\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinalg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstsq\u001B[49m\u001B[43m(\u001B[49m\u001B[43mM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mr\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.11.3/lib/python3.11/site-packages/scipy/linalg/_basic.py:1213\u001B[0m, in \u001B[0;36mlstsq\u001B[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001B[0m\n\u001B[1;32m   1211\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m real_data:\n\u001B[1;32m   1212\u001B[0m     lwork, iwork \u001B[38;5;241m=\u001B[39m _compute_lwork(lapack_lwork, m, n, nrhs, cond)\n\u001B[0;32m-> 1213\u001B[0m     x, s, rank, info \u001B[38;5;241m=\u001B[39m \u001B[43mlapack_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mb1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlwork\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1214\u001B[0m \u001B[43m                                   \u001B[49m\u001B[43miwork\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcond\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# complex data\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m     lwork, rwork, iwork \u001B[38;5;241m=\u001B[39m _compute_lwork(lapack_lwork, m, n,\n\u001B[1;32m   1217\u001B[0m                                          nrhs, cond)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: fit sklearn stacked model\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from itertools import chain, combinations\n",
    "\n",
    "from sklearn.linear_model import QuantileRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return list(chain.from_iterable(combinations(s, r) for r in range(len(s)+1)))\n",
    "\n",
    "results = []\n",
    "\n",
    "def stacking_regressor_helper(estimators):\n",
    "    for set in tqdm(powerset(estimators)):\n",
    "        if not set:\n",
    "            continue\n",
    "\n",
    "        set = [x for x in set]\n",
    "        # print(type(set), set)\n",
    "\n",
    "        print(\"Training:\", [a[0] for a in set])\n",
    "\n",
    "        reg = StackingRegressor(\n",
    "            estimators=set,\n",
    "            final_estimator=LinearRegression()\n",
    "        )\n",
    "\n",
    "        reg.fit(X, y)\n",
    "\n",
    "        # TODO: evaluate with crossvalidation, compare to custom model\n",
    "        # print(\", \".join([a[0] for a in set]))\n",
    "        results.append(\n",
    "            ([a[0] for a in set], np.mean(cross_val_score(reg, X, y, cv=10)))\n",
    "        )\n",
    "\n",
    "estimators = [\n",
    "    ('Linear Regression', linear_regression),\n",
    "    ('Polynomial Regression', polynomial_regression),\n",
    "    ('KNN Regression', knn_regression),\n",
    "    ('Paul ist cool ðŸ˜Ž', dtree_regression),\n",
    "    ('Kernel Ridge', KernelRidge()),\n",
    "    ('Quantile Regressor', QuantileRegressor())\n",
    "]\n",
    "stacking_regressor_helper(estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6550fa29",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "Try at least two different combinations of regressors for base models and meta model and report the average crossvalidation score.\n",
    "[Here](https://scikit-learn.org/stable/supervised_learning.html) you can find an overview page of sklearn estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7839301f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T14:51:11.661998671Z",
     "start_time": "2023-06-21T14:51:11.649137259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                    0         1\n0                                 [Linear Regression]  0.236917\n1                             [Polynomial Regression]  0.168551\n2                                    [KNN Regression]  0.000667\n3                                   [Paul ist cool ðŸ˜Ž]  0.026877\n4                                      [Kernel Ridge]  0.237912\n5          [Linear Regression, Polynomial Regression]  0.242760\n6                 [Linear Regression, KNN Regression]  0.237251\n7                [Linear Regression, Paul ist cool ðŸ˜Ž]  0.238822\n8                   [Linear Regression, Kernel Ridge]  0.236933\n9             [Polynomial Regression, KNN Regression]  0.178466\n10           [Polynomial Regression, Paul ist cool ðŸ˜Ž]  0.188699\n11              [Polynomial Regression, Kernel Ridge]  0.245844\n12                  [KNN Regression, Paul ist cool ðŸ˜Ž]  0.086355\n13                     [KNN Regression, Kernel Ridge]  0.237627\n14                    [Paul ist cool ðŸ˜Ž, Kernel Ridge]  0.243751\n15  [Linear Regression, Polynomial Regression, KNN...  0.242707\n16  [Linear Regression, Polynomial Regression, Pau...  0.246437\n17  [Linear Regression, Polynomial Regression, Ker...  0.242253\n18  [Linear Regression, KNN Regression, Paul ist c...  0.237833\n19  [Linear Regression, KNN Regression, Kernel Ridge]  0.237078\n20  [Linear Regression, Paul ist cool ðŸ˜Ž, Kernel Ri...  0.234671\n21  [Polynomial Regression, KNN Regression, Paul i...  0.189906\n22  [Polynomial Regression, KNN Regression, Kernel...  0.245342\n23  [Polynomial Regression, Paul ist cool ðŸ˜Ž, Kerne...  0.249566\n24    [KNN Regression, Paul ist cool ðŸ˜Ž, Kernel Ridge]  0.238631\n25  [Linear Regression, Polynomial Regression, KNN...  0.246559\n26  [Linear Regression, Polynomial Regression, KNN...  0.242178\n27  [Linear Regression, Polynomial Regression, Pau...  0.243167\n28  [Linear Regression, KNN Regression, Paul ist c...  0.239522\n29  [Polynomial Regression, KNN Regression, Paul i...  0.244854\n30  [Linear Regression, Polynomial Regression, KNN...  0.244638",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[Linear Regression]</td>\n      <td>0.236917</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[Polynomial Regression]</td>\n      <td>0.168551</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[KNN Regression]</td>\n      <td>0.000667</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[Paul ist cool ðŸ˜Ž]</td>\n      <td>0.026877</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[Kernel Ridge]</td>\n      <td>0.237912</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[Linear Regression, Polynomial Regression]</td>\n      <td>0.242760</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[Linear Regression, KNN Regression]</td>\n      <td>0.237251</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[Linear Regression, Paul ist cool ðŸ˜Ž]</td>\n      <td>0.238822</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[Linear Regression, Kernel Ridge]</td>\n      <td>0.236933</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[Polynomial Regression, KNN Regression]</td>\n      <td>0.178466</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>[Polynomial Regression, Paul ist cool ðŸ˜Ž]</td>\n      <td>0.188699</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>[Polynomial Regression, Kernel Ridge]</td>\n      <td>0.245844</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>[KNN Regression, Paul ist cool ðŸ˜Ž]</td>\n      <td>0.086355</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>[KNN Regression, Kernel Ridge]</td>\n      <td>0.237627</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>[Paul ist cool ðŸ˜Ž, Kernel Ridge]</td>\n      <td>0.243751</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>[Linear Regression, Polynomial Regression, KNN...</td>\n      <td>0.242707</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>[Linear Regression, Polynomial Regression, Pau...</td>\n      <td>0.246437</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>[Linear Regression, Polynomial Regression, Ker...</td>\n      <td>0.242253</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>[Linear Regression, KNN Regression, Paul ist c...</td>\n      <td>0.237833</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>[Linear Regression, KNN Regression, Kernel Ridge]</td>\n      <td>0.237078</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>[Linear Regression, Paul ist cool ðŸ˜Ž, Kernel Ri...</td>\n      <td>0.234671</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>[Polynomial Regression, KNN Regression, Paul i...</td>\n      <td>0.189906</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>[Polynomial Regression, KNN Regression, Kernel...</td>\n      <td>0.245342</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>[Polynomial Regression, Paul ist cool ðŸ˜Ž, Kerne...</td>\n      <td>0.249566</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>[KNN Regression, Paul ist cool ðŸ˜Ž, Kernel Ridge]</td>\n      <td>0.238631</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>[Linear Regression, Polynomial Regression, KNN...</td>\n      <td>0.246559</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>[Linear Regression, Polynomial Regression, KNN...</td>\n      <td>0.242178</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>[Linear Regression, Polynomial Regression, Pau...</td>\n      <td>0.243167</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>[Linear Regression, KNN Regression, Paul ist c...</td>\n      <td>0.239522</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>[Polynomial Regression, KNN Regression, Paul i...</td>\n      <td>0.244854</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>[Linear Regression, Polynomial Regression, KNN...</td>\n      <td>0.244638</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: try different combinations\n",
    "\n",
    "# see task 6\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1315e6714f2518a6216a6eec3b047587d10875bf19b853b35d3e5c84c569e2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
