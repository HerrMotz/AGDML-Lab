{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise 2 - Polynomial Regression\n",
    "\n",
    "In this exercise you will learn about a new type of regression - the polynomial regression. With polynomial regression it is possible to fit a nonlinear relationship between the dependent and the independent variables, although the problem of estimating the parameters is linear and can be solved with the standard linear regression approach.\n",
    "\n",
    "The idea here is to learn a bunch of (polynomial) models on the same data set and explore the meaning of over- and underfitting the data.\n",
    "\n",
    "In a second part, we will use Leave One Out Crossvalidation to find a good regularization parameter on the Boston Housing dataset.\n",
    "\n",
    "In the event of a persistent problem, do not hesitate to contact the course instructor under\n",
    "\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "- Deadline of submission:\n",
    "        26.04.23 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=43681)\n",
    "\n",
    "\n",
    "### Help\n",
    "In case you cannot solve a task, you can use the saved values within the `help` directory:\n",
    "- Load arrays with [Numpy](https://numpy.org/doc/stable/reference/generated/numpy.load.html)\n",
    "```\n",
    "np.load('help/array_name.npy')\n",
    "```\n",
    "- Load functions with [Dill](https://dill.readthedocs.io/en/latest/dill.html)\n",
    "```\n",
    "import dill\n",
    "with open('help/some_func.pkl', 'rb') as f:\n",
    "    func = dill.load(f)\n",
    "```\n",
    "\n",
    "to continue working on the other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We now have a new dataset saved as `train.npy`.\n",
    "\n",
    "### Task 1\n",
    "Load this Dataset using the [`np.load`](https://numpy.org/doc/stable/reference/generated/numpy.load.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load train.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns of the dataset represent the variables. Let `X` be the explanatory variable in the first column and `Y` be the variable we want to predict in the second column. \n",
    "\n",
    "### Task 2\n",
    "Visualize the data with a scatterplot of `X` against `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scatter plot the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Regression\n",
    "As you can see, the relationship between the dependent variable and the explanatory one does not seem to be linear and the standard linear regression from the lecture will not perform well. One way to account for such a non linear relationship is called [polynomial regression](https://en.wikipedia.org/wiki/Polynomial_regression). For a scalar explanatory variable `X` and a scalar dependent variable `Y`, the data generation model is:\n",
    "\n",
    "$$\n",
    "Y = \\theta_0 + \\theta_1 * X + \\theta_2 X^2 + \\dots + \\theta_d X^d  + \\epsilon = \\sum_{j=0}^d \\theta_j X^j + \\epsilon\n",
    "$$\n",
    "where $d$ is called degree. Similar to linear regression, we assume $\\varepsilon$ to be standard normal distributed noise.\n",
    "\n",
    "Although the relationship between the dependent and the explanatory variable is non linear, the problem of estimating the parameters $\\theta$ is linear. By vectorizing the model, this becomes obvious:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    Y_1 \\\\\n",
    "    Y_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    Y_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "    \\theta_0 \\\\\n",
    "    \\theta_1 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\theta_d\n",
    "\\end{bmatrix}^T\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & \\dots & 1\\\\\n",
    "    X_1 & X_2 & \\dots & X_n\\\\\n",
    "    \\vdots&\\vdots&\\vdots&\\vdots\\\\\n",
    "    X_1^d & X_2^d &\\dots & X_n^d\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "    \\epsilon_1 \\\\\n",
    "    \\epsilon_2 \\\\\n",
    "    \\vdots \\\\\n",
    "    \\epsilon_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This linear model can now be fit with the linear regression approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "Implement a function `poly` to create the design matrix for the polynomial regression. \n",
    "\n",
    "Verify the correctness of your implementation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly(X : np.ndarray, degree : int) -> np.ndarray:\n",
    "    '''\n",
    "    Creates the polynomial design matrix.\n",
    "    \n",
    "    @Params:\n",
    "        X... array of scalar x\n",
    "        degree... polynomial degree\n",
    "        \n",
    "    @Returns:\n",
    "        Design matrix\n",
    "    '''\n",
    "    \n",
    "    #TODO: implement\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Implement a class `PolyReg` that fits a polynomial model with ordinary least squares. Regularize your maximum-likelihood problem with ridge regression.\n",
    "\n",
    "Hint: Recycle the `LinReg` class from the last exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolyReg():\n",
    "    def __init__(self, d : int, c : int = 0):\n",
    "        '''\n",
    "        Class for polynomial regression.\n",
    "        \n",
    "        @Params:\n",
    "            d... polynomial degree\n",
    "            c... parameter for ridge regression\n",
    "        '''\n",
    "        # TODO: create attributes d, c, theta \n",
    "        pass\n",
    "    \n",
    "    def fit(self, X : np.ndarray, Y : np.ndarray):\n",
    "        '''\n",
    "        Learns the parameters for a polynomial regression task.\n",
    "        \n",
    "        @Params:\n",
    "            X... array of scalar x (explanatory variable)\n",
    "            Y... array of scalar y (dependent variable)\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X : np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Using learned parameters, predicts output for given X.\n",
    "        \n",
    "        @Params:\n",
    "            X... array of scalar x (explanatory variable)\n",
    "            \n",
    "        @Returns:\n",
    "            Y... array of scalar y (dependent variable)\n",
    "        '''\n",
    "        # TODO: implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Next we want to fit a series of models of multiple degrees and visualise them alongside the data.\n",
    "\n",
    "We want to use the following polynomial degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model degrees\n",
    "model_degrees = [0, 1, 2, 3, 6, 9, 12, 15, 18, 21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "For each polynomial degree:\n",
    "1. Learn the polynomial model\n",
    "2. Plot the data \n",
    "3. Plot the regression line\n",
    "\n",
    "Plot each model in a separate [subplot](https://matplotlib.org/3.5.0/api/_as_gen/matplotlib.pyplot.subplots.html). Use a scatter plot for the data.\n",
    "\n",
    "Additionaly experiment what happens if you change the values for the regularization parameter $c$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Learn models and visualize regression lines\n",
    "\n",
    "# TODO: What effect does c have on the regression lines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "To evaluate the models, we need a measure of fit, that tells us how well the model fits the data. The standard measure for continuously distributed data is the [\"root mean squared error\" (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation). Given the dependent variable $Y \\in \\mathbb{R}^n$ and its prediction $\\hat{Y} = f(X, \\theta) \\in \\mathbb{R}^n$, the RMSE is defined as:\n",
    "\n",
    "$$\n",
    "\\text{RMSE}(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n} \\sum_{i}^n (Y_i - \\hat{Y}_i)^2}\n",
    "$$\n",
    "\n",
    "### Task 6\n",
    "Implement a `rmse` function that returns the RMSE of a vector of observations $Y$ and its predictions $\\hat{Y}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(Y : np.ndarray, Y_hat : np.ndarray) -> float:\n",
    "    '''\n",
    "    Calculates the root means squared error (rmse) of Y and its prediction Y_hat.\n",
    "    \n",
    "    @Params:\n",
    "        Y... array of true dependend variable\n",
    "        Y_hat... array of predicted dependend variable\n",
    "    \n",
    "    @Returns:\n",
    "        RMSE(Y, Y_hat)\n",
    "    '''\n",
    "    # TODO: calculate RMSE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to estimate which polynomial estimation fits best to our data.\n",
    "More complex models will in general yield better results on the data that was used to train them, but the quality of the model is determined by its \"generalizability\" (\"how well does the model perform on data that it has not seen before?\"). \n",
    "\n",
    "To evaluate this performance, we split the data in two sets:\n",
    "- trainset (`train.npy`)\n",
    "- testset (`test.npy`)\n",
    "\n",
    "where we train our predictor on the trainset and evaluate the generalizability on the testset.\n",
    "\n",
    "### Task 7\n",
    "\n",
    "Load the testset (stored as `test.npy`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "To estimate the quality of our models:\n",
    "- fit 20 polynomial models of degree 0 to 19 on the trainset.\n",
    "- calculate the RMSE of all the models on the trainset.\n",
    "- calculate the RMSE of all the models on the testset.\n",
    "\n",
    "Set the regularization parameter to some fixed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate train- and test RMSEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "Now visualize the training RMSE and testing RMSE in dependence of the degree of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot RMSEs against polynomial degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the two curves of the previously generated figure you can determine the fit of the models.\n",
    "\n",
    "- Underfitting: train- and test RMSE are high\n",
    "- Overfitting: train RMSE is low, test RMSE is high\n",
    "- Just right: train- and test RMSE are low\n",
    "\n",
    "### Task 10\n",
    "List briefly:\n",
    "- which models underfit\n",
    "- which models overfit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: when does it overfit, underfit?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
