{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Linear Regression\n",
    "\n",
    "The first exercise is about linear models.\n",
    "The given data set contains prices and other attributes of approximately 54,000 diamonds. You should fit a linear model to predict the price of a diamond, given its attributes.\n",
    "\n",
    "This exercise is meant to get you started with the tool stack. Besides numpy and matplotlib we use the following python packages:\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/)\n",
    "- [sklearn](http://scikit-learn.org/)\n",
    "\n",
    "If you are unfamiliar with them, follow the documentation links. \n",
    "\n",
    "In the event of a persistent problem, do not hesitate to contact the course instructor under\n",
    "\n",
    "- paul.kahlmeyer@uni-jena.de\n",
    "\n",
    "### Submission\n",
    "- Deadline of submission:\n",
    "        19.04.23 23:59\n",
    "- Submission on [moodle page](https://moodle.uni-jena.de/course/view.php?id=43681)\n",
    "\n",
    "\n",
    "### Help\n",
    "In case you cannot solve a task, you can use the saved values within the `help` directory:\n",
    "- Load arrays with [Numpy](https://numpy.org/doc/stable/reference/generated/numpy.load.html)\n",
    "```\n",
    "np.load('help/array_name.npy')\n",
    "```\n",
    "- Load functions with [Dill](https://dill.readthedocs.io/en/latest/dill.html)\n",
    "```\n",
    "import dill\n",
    "with open('help/some_func.pkl', 'rb') as f:\n",
    "    func = dill.load(f)\n",
    "```\n",
    "\n",
    "to continue working on the other tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We use the same notation as in the lecture.\n",
    "- $m$... Number of datapoints\n",
    "- $n$... Number of features\n",
    "\n",
    "### Dataset \n",
    "\n",
    "As a dataset, we use the [diamond dataset](https://www.kaggle.com/shivam2503/diamonds).\n",
    "\n",
    "Each element in this dataset represents a diamond and has the following features:\n",
    "\n",
    "- price: price in US dollars (326.0 - 18823.0)\n",
    "- carat: weight of the diamond (0.2 - 5.01)\n",
    "- cut: quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "- color: diamond colour, from J (worst) to D (best)\n",
    "- clarity: a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "- x: length in mm (0-10.74)\n",
    "- y: width in mm (0-58.9)\n",
    "- z: depth in mm (0-31.8)\n",
    "- depth: total depth percentage = 2 * z / (x + y) (43-79)\n",
    "- table: width of top of diamond relative to widest point (43-95)\n",
    "\n",
    "The dataset is stored under `diamonds.csv`.\n",
    "\n",
    "### Task 1\n",
    "Import the data from the file using [pandas](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) and examine it.\n",
    "\n",
    "Determine the following:\n",
    "\n",
    "* The number of data points\n",
    "* The column names\n",
    "* The data types for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:30.648167Z",
     "end_time": "2023-04-16T15:33:32.174054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size 539400\n",
      "<bound method DataFrame.info of        carat        cut color clarity  depth  table  price     x     y     z\n",
      "0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
      "1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
      "2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
      "3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
      "4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
      "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
      "53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
      "53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
      "53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
      "53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
      "53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
      "\n",
      "[53940 rows x 10 columns]>\n",
      "Index(['carat', 'cut', 'color', 'clarity', 'depth', 'table', 'price', 'x', 'y',\n",
      "       'z'],\n",
      "      dtype='object')\n",
      "carat      float64\n",
      "cut         object\n",
      "color       object\n",
      "clarity     object\n",
      "depth      float64\n",
      "table      float64\n",
      "price        int64\n",
      "x          float64\n",
      "y          float64\n",
      "z          float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": "       carat        cut color clarity  depth  table  price     x     y     z\n0       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n53935   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n53936   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n53937   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n53938   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n53939   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n\n[53940 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>price</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.23</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>61.5</td>\n      <td>55.0</td>\n      <td>326</td>\n      <td>3.95</td>\n      <td>3.98</td>\n      <td>2.43</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>Premium</td>\n      <td>E</td>\n      <td>SI1</td>\n      <td>59.8</td>\n      <td>61.0</td>\n      <td>326</td>\n      <td>3.89</td>\n      <td>3.84</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.23</td>\n      <td>Good</td>\n      <td>E</td>\n      <td>VS1</td>\n      <td>56.9</td>\n      <td>65.0</td>\n      <td>327</td>\n      <td>4.05</td>\n      <td>4.07</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.29</td>\n      <td>Premium</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.4</td>\n      <td>58.0</td>\n      <td>334</td>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>2.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.31</td>\n      <td>Good</td>\n      <td>J</td>\n      <td>SI2</td>\n      <td>63.3</td>\n      <td>58.0</td>\n      <td>335</td>\n      <td>4.34</td>\n      <td>4.35</td>\n      <td>2.75</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>53935</th>\n      <td>0.72</td>\n      <td>Ideal</td>\n      <td>D</td>\n      <td>SI1</td>\n      <td>60.8</td>\n      <td>57.0</td>\n      <td>2757</td>\n      <td>5.75</td>\n      <td>5.76</td>\n      <td>3.50</td>\n    </tr>\n    <tr>\n      <th>53936</th>\n      <td>0.72</td>\n      <td>Good</td>\n      <td>D</td>\n      <td>SI1</td>\n      <td>63.1</td>\n      <td>55.0</td>\n      <td>2757</td>\n      <td>5.69</td>\n      <td>5.75</td>\n      <td>3.61</td>\n    </tr>\n    <tr>\n      <th>53937</th>\n      <td>0.70</td>\n      <td>Very Good</td>\n      <td>D</td>\n      <td>SI1</td>\n      <td>62.8</td>\n      <td>60.0</td>\n      <td>2757</td>\n      <td>5.66</td>\n      <td>5.68</td>\n      <td>3.56</td>\n    </tr>\n    <tr>\n      <th>53938</th>\n      <td>0.86</td>\n      <td>Premium</td>\n      <td>H</td>\n      <td>SI2</td>\n      <td>61.0</td>\n      <td>58.0</td>\n      <td>2757</td>\n      <td>6.15</td>\n      <td>6.12</td>\n      <td>3.74</td>\n    </tr>\n    <tr>\n      <th>53939</th>\n      <td>0.75</td>\n      <td>Ideal</td>\n      <td>D</td>\n      <td>SI2</td>\n      <td>62.2</td>\n      <td>55.0</td>\n      <td>2757</td>\n      <td>5.83</td>\n      <td>5.87</td>\n      <td>3.64</td>\n    </tr>\n  </tbody>\n</table>\n<p>53940 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: load data\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"diamonds.csv\")\n",
    "\n",
    "# TODO: determine number of datapoints\n",
    "print(\"dataset size\", df.size)\n",
    "print(df.info)\n",
    "\n",
    "# TODO: determine column names\n",
    "col_names = df.columns\n",
    "print(col_names)\n",
    "\n",
    "# TODO: determine datatypes of columns\n",
    "dtypes = df.dtypes\n",
    "print(dtypes)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Since there are discrete variables and we do not yet know how to include them into our regression model, remove them. Additionally, verify that there are no missing values in our dataset.\n",
    "\n",
    "Hint: there are multiple ways to [check](https://towardsdatascience.com/how-to-check-for-missing-values-in-pandas-d2749e45a345) for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.171051Z",
     "end_time": "2023-04-16T15:33:32.177267Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# TODO: remove discrete variables\n",
    "if \"cut\" in df.columns:\n",
    "    df.drop(\"cut\", axis=1)\n",
    "    df.drop(\"color\", axis=1)\n",
    "    df.drop(\"clarity\", axis=1)\n",
    "\n",
    "# check for missing values\n",
    "assert not np.isnan(df.values).any(), \"There are missing values!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the lecture, we should **standardize** the data, to make different scales comparable.\n",
    "\n",
    "Standardization is defined for each feature $x_i$:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{x}_i = \\cfrac{x_i-\\mu_x}{\\sigma_x}\\,,\n",
    "\\end{align}\n",
    "where $\\mu_x$ and $\\sigma_x$ are the empirical [mean](https://en.wikipedia.org/wiki/Mean) and [standard deviation](https://en.wikipedia.org/wiki/Standard_deviation) of the feature $x$.\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Convert the pandas dataframe to a numpy array and calculate the standardized data matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def pm(title: str, a: np.ndarray) -> None:\n",
    "    print(f\"\\n{title} {a.shape}\")\n",
    "    print(a)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T16:43:46.620652Z",
     "end_time": "2023-04-16T16:43:46.646234Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T17:12:50.135274Z",
     "end_time": "2023-04-16T17:12:50.154250Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "empirical mean μ (6,)\n",
      "[ 0.79793975 61.74940489 57.45718391  5.73115721  5.73452595  3.53873378]\n",
      "\n",
      "features X_original (53940, 6)\n",
      "[[ 0.23 61.5  55.    3.95  3.98  2.43]\n",
      " [ 0.21 59.8  61.    3.89  3.84  2.31]\n",
      " [ 0.23 56.9  65.    4.05  4.07  2.31]\n",
      " ...\n",
      " [ 0.7  62.8  60.    5.66  5.68  3.56]\n",
      " [ 0.86 61.   58.    6.15  6.12  3.74]\n",
      " [ 0.75 62.2  55.    5.83  5.87  3.64]]\n",
      "\n",
      "standard deviation σ (6,)\n",
      "[0.22468249 2.05236579 4.99285551 1.25832384 1.30444743 0.49800163]\n",
      "\n",
      "transformed features X (53940, 6)\n",
      "[[-2.52774365 -0.12152068 -0.49214    -1.41549985 -1.34503385 -2.22636576]\n",
      " [-2.61675815 -0.94983307  0.70957713 -1.46318233 -1.45235899 -2.46732883]\n",
      " [-2.52774365 -2.36283654  1.51072189 -1.33602905 -1.27603912 -2.46732883]\n",
      " ...\n",
      " [-0.43590289  0.51189467  0.50929094 -0.0565492  -0.04180004  0.04270312]\n",
      " [ 0.27621312 -0.36514197  0.10871857  0.33285771  0.29550754  0.40414772]\n",
      " [-0.21336664  0.21954912 -0.49214     0.07855115  0.1038555   0.20334516]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate standardized data matrix X\n",
    "X_orig = np.array(df.loc[:, df.columns != \"price\"])\n",
    "rows = X_orig.shape[0]\n",
    "\n",
    "# empirical mean / Erwartungswert\n",
    "M = np.einsum('ij->j', X_orig) / rows\n",
    "pm(\"empirical mean μ\", M)\n",
    "\n",
    "pm(\"features X_original\", X_orig)\n",
    "\n",
    "S = X_orig - M\n",
    "S *= S\n",
    "S = np.sum(S, axis=0)\n",
    "S /= rows\n",
    "pm(\"standard deviation σ\", S)\n",
    "\n",
    "X = (X_orig - M) / S\n",
    "pm(\"transformed features X\", X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "# test equivalence of operations\n",
    "for i in np.arange(X.shape[0]):\n",
    "    for j in np.arange(X.shape[1]):\n",
    "        assert X[i,j] == (X_orig[i,j] - M[j]) / S[j]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-16T17:10:33.015553Z",
     "end_time": "2023-04-16T17:10:33.435603Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "Scikit learn has an [implementation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) of this preprocessing.\n",
    "\n",
    "Use it to create a second standardized data matrix and compare this result with your result from Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T17:18:39.228393Z",
     "end_time": "2023-04-16T17:18:39.250077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean old (6,)\n",
      "[ 0.79793975 61.74940489 57.45718391  5.73115721  5.73452595  3.53873378]\n",
      "\n",
      "Mean Skl (6,)\n",
      "[ 0.79793975 61.74940489 57.45718391  5.73115721  5.73452595  3.53873378]\n",
      "\n",
      "Mean dif (6,)\n",
      "[ 3.10862447e-15  0.00000000e+00  0.00000000e+00 -4.44089210e-15\n",
      " -7.10542736e-15  8.88178420e-16]\n",
      "\n",
      "Std old (6,)\n",
      "[0.22468249 2.05236579 4.99285551 1.25832384 1.30444743 0.49800163]\n",
      "\n",
      "Std Skl (6,)\n",
      "[0.22468249 2.05236579 4.99285551 1.25832384 1.30444743 0.49800163]\n",
      "\n",
      "Std dif (6,)\n",
      "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.66533454e-16]\n",
      "\n",
      "sklearn scaler (53940, 6)\n",
      "[[-1.19816781 -0.17409151 -1.09967199 -1.58783745 -1.53619556 -1.57112919]\n",
      " [-1.24036129 -1.36073849  1.58552871 -1.64132529 -1.65877419 -1.74117497]\n",
      " [-1.19816781 -3.38501862  3.37566251 -1.49869105 -1.45739502 -1.74117497]\n",
      " ...\n",
      " [-0.20662095  0.73334442  1.13799526 -0.06343409 -0.04774083  0.03013526]\n",
      " [ 0.13092691 -0.52310533  0.24292836  0.37338325  0.33750627  0.28520393]\n",
      " [-0.10113725  0.31452784 -1.09967199  0.08811478  0.11861587  0.14349912]]\n",
      "\n",
      "old scale (53940, 6)\n",
      "[[-2.52774365 -0.12152068 -0.49214    -1.41549985 -1.34503385 -2.22636576]\n",
      " [-2.61675815 -0.94983307  0.70957713 -1.46318233 -1.45235899 -2.46732883]\n",
      " [-2.52774365 -2.36283654  1.51072189 -1.33602905 -1.27603912 -2.46732883]\n",
      " ...\n",
      " [-0.43590289  0.51189467  0.50929094 -0.0565492  -0.04180004  0.04270312]\n",
      " [ 0.27621312 -0.36514197  0.10871857  0.33285771  0.29550754  0.40414772]\n",
      " [-0.21336664  0.21954912 -0.49214     0.07855115  0.1038555   0.20334516]]\n",
      "\n",
      "Deviation between scalers (53940, 6)\n",
      "[[-1.32957584  0.05257082  0.60753199  0.1723376   0.19116171 -0.65523657]\n",
      " [-1.37639686  0.41090542 -0.87595158  0.17814296  0.2064152  -0.72615386]\n",
      " [-1.32957584  1.02218208 -1.86494062  0.162662    0.1813559  -0.72615386]\n",
      " ...\n",
      " [-0.22928193 -0.22144975 -0.62870431  0.00688489  0.00594079  0.01256786]\n",
      " [ 0.14528621  0.15796335 -0.13420979 -0.04052554 -0.04199874  0.11894378]\n",
      " [-0.11222939 -0.09497871  0.60753199 -0.00956363 -0.01476037  0.05984605]]\n",
      "\n",
      "Deviation between scalers with 1/2 * X (53940, 6)\n",
      "[[-0.06570402  0.11333117  0.85360199  0.88008752  0.86367864  0.45794631]\n",
      " [-0.06801779  0.88582195 -1.23074014  0.90973412  0.93259469  0.50751055]\n",
      " [-0.06570402  2.20360035 -2.62030156  0.83067653  0.81937546  0.50751055]\n",
      " ...\n",
      " [-0.01133049 -0.47739708 -0.88334979  0.03515949  0.02684081 -0.0087837 ]\n",
      " [ 0.00717965  0.34053434 -0.18856908 -0.20695439 -0.18975251 -0.08313008]\n",
      " [-0.00554607 -0.20475328  0.85360199 -0.04883921 -0.06668812 -0.04182654]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: compare to sklearn result\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "diamond_scaler = scaler.fit(X_orig)\n",
    "\n",
    "\n",
    "pm(\"Mean old\", M)\n",
    "pm(\"Mean Skl\", diamond_scaler.mean_)\n",
    "pm(\"Mean dif\", M - diamond_scaler.mean_)\n",
    "\n",
    "pm(\"Std old\", S)\n",
    "pm(\"Std Skl\", diamond_scaler.var_)\n",
    "pm(\"Std dif\", S - diamond_scaler.var_)\n",
    "\n",
    "X2 = diamond_scaler.transform(X_orig)\n",
    "\n",
    "pm(\"sklearn scaler\", X2)\n",
    "pm(\"old scale\", X)\n",
    "\n",
    "Deviation = X - X2\n",
    "pm(\"Deviation between scalers\", Deviation)\n",
    "\n",
    "Deviation2 = (X/2) - X2\n",
    "pm(\"Deviation between scalers with 1/2 * X\", Deviation2)\n",
    "\n",
    "# TODO: I do not understand why the results differ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Data\n",
    "\n",
    "Visualizing correlation in your data often helps to build intuition and get a feeling of the deeper mojo in the set.\n",
    "\n",
    "Here we want to use the [Pearson correlation coefficient](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient) as a measure for correlation between two variables.\n",
    "\n",
    "Let $x$ and $y$ be two variables of the unstandardized dataset (e.g. `carat` and `price`). The empirical Pearson correlation coefficient between $x$ and $y$ is defined as \n",
    "\n",
    "\\begin{align}\n",
    "r_{xy} = \\cfrac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\,,\n",
    "\\end{align}\n",
    "where $\\bar{x}$ and $\\bar{y}$ are the respective empirical means.\n",
    "\n",
    "### Task 5\n",
    "\n",
    "How does this definition translate to our standardized data matrix $X$?\n",
    "\n",
    "Calculate the pairwise correlation matrix for our dataset. \n",
    "\n",
    "Visualize this correlation matrix and label the rows/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.191081Z",
     "end_time": "2023-04-16T15:33:32.229902Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: calculate correlation matrix\n",
    "\n",
    "# TODO: visualize correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Our goal in this exercise will be to predict the `price` of a diamond based on some of its other features.\n",
    "\n",
    "We will use linear regression, that is we assume the `price` (=$y$) depends linearly on the other features (=$\\mathbf{x}$):\n",
    "\\begin{align}\n",
    "y = \\theta^T \\mathbf{x} + \\varepsilon\n",
    "\\end{align}\n",
    "where $\\varepsilon$ is standard normal distributed noise.\n",
    "\n",
    "In `Linear_Regression_Script.pdf` you find how the maximum likelihood estimate $\\hat\\theta$ is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "Implement a `LinReg` class that uses maximum likelihood estimation. Add the possibility to use [Ridge Regression](https://en.wikipedia.org/wiki/Ridge_regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.200862Z",
     "end_time": "2023-04-16T15:33:32.231016Z"
    }
   },
   "outputs": [],
   "source": [
    "class LinReg():\n",
    "    \n",
    "    def __init__(self, c:int = 0):\n",
    "        '''\n",
    "        Class for linear regression.\n",
    "        \n",
    "        @Params:\n",
    "            c... parameter for ridge regression\n",
    "        '''\n",
    "        # TODO: create attributes: c, theta \n",
    "        pass\n",
    "    \n",
    "    def fit(self, X:np.ndarray, Y:np.ndarray) -> None:\n",
    "        '''\n",
    "        Learns the parameters for a linear regression task.\n",
    "        \n",
    "        @Params:\n",
    "            X... n x m matrix\n",
    "            Y... vector of length m\n",
    "        '''\n",
    "        \n",
    "        # TODO: estimate theta\n",
    "        pass\n",
    "        \n",
    "    def predict(self, X:np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        Using learned parameters, predicts output for given X.\n",
    "        \n",
    "        @Params:\n",
    "            X... n x m matrix\n",
    "            Y... vector of length m\n",
    "        '''\n",
    "        \n",
    "        # TODO: predict labels\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "First we want to predict the `price` of a diamond solely from the variable `carat`. \n",
    "Make a scatter plot of `carat` vs `price` using matplotlib. Label the axes and give the plot a title.\n",
    "\n",
    "Use the standardized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.216340Z",
     "end_time": "2023-04-16T15:33:32.260581Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: display data in scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "Set up the design matrix and use your class to estimate $\\theta$ on the dataset.\n",
    "Note, that the design matrix does **not** need the vector of ones, since we standardized the dataset.\n",
    "\n",
    "Plot the regression line defined by $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.228909Z",
     "end_time": "2023-04-16T15:33:32.311223Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: build design matrix, y\n",
    "\n",
    "# TODO: use Linear Regression\n",
    "\n",
    "# TODO: plot data + regression line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "You can find an implementation of this method in the python module [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Use it and compare your result for the estimation of $\\theta$.\n",
    "\n",
    "**Important:** scikit learn needs the design matrix as a $m \\times n$ matrix (datapoints as rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.239361Z",
     "end_time": "2023-04-16T15:33:32.312227Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: use scikit learn to estimate theta\n",
    "\n",
    "# TODO: compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "Now predict the `price` from the variables `carat`, `depth`, `table`, `x`, `y`, `z`.\n",
    "\n",
    "- Estimate $\\theta$ with your class\n",
    "- Estimate $\\theta$ with scikit learn\n",
    "- Compare both estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-16T15:33:32.247229Z",
     "end_time": "2023-04-16T15:33:32.337439Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: build X, Y\n",
    "\n",
    "# TODO: estimate theta\n",
    "\n",
    "# TODO: estimate theta using scikit-learn + compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
